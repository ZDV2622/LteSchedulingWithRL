{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Parameters\n",
    "import PGAgent\n",
    "import InputTrafficGeneration\n",
    "import Envirement\n",
    "from  Envirement import Envirement as env\n",
    "import LearnPGagent as lpg\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start learning process\n",
    "# for this simulation it was taken: UE=7, QCI_n = 3, CQI is randomly generated for each RBG and SF\n",
    "\n",
    "SF = 200000       # number of SF for learning process\n",
    "sfi_train = 1           # how often model wil be traind - number of SF\n",
    "sfi_save = 20000       # how often to save trained model\n",
    "sfi_show_reward = 2000  # how often to show results\n",
    "\n",
    "rew_sf_rand, rew_sf_DQN, rew_sf_BestCQI, QCI_usage  = lpg.LearnProcessPgagent(SF,sfi_train,sfi_save,sfi_show_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning process for PGagent\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "leng = 40000\n",
    "x_rand = rew_sf_rand[0:leng]\n",
    "x_DQN = rew_sf_DQN[0:leng]\n",
    "x_BestCQI = rew_sf_BestCQI[0:leng]\n",
    "#x_QCI1_usage = CQI_usage[0:leng][1]\n",
    "sf_avg = 500\n",
    "avg_reward_rand =[(x_rand[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_rand),sf_avg)]\n",
    "avg_reward_rand = np.array(avg_reward_rand)\n",
    "avg_reward_DQN =[(x_DQN[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_DQN),sf_avg)]\n",
    "avg_reward_DQN = np.array(avg_reward_DQN)\n",
    "avg_reward_BestCQI =[(x_BestCQI[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_BestCQI),sf_avg)]\n",
    "avg_reward_BestCQI = np.array(avg_reward_BestCQI)\n",
    "i = np.arange(0,len(avg_reward_DQN),1)\n",
    "y_rand = avg_reward_rand[i]\n",
    "y_DQN = avg_reward_DQN[i]\n",
    "y_BestCQI = avg_reward_BestCQI[i]\n",
    "\n",
    "plt.title(\"Reward in subframe (7 UE with randomly generated CQI, 4 QCI)\")\n",
    "plt.xlabel(\"episod\")\n",
    "plt.ylabel(\"reward\") \n",
    "plt.grid()\n",
    "plt.plot(i, y_BestCQI, label='BestCQI reward',marker='h',color = 'r') \n",
    "plt.plot(i, y_rand, label='Round Robin reward',marker='o',color = 'cornflowerblue')\n",
    "plt.plot(i, y_DQN, label='PGagent reward',marker='x',color = 'limegreen')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "leng = 7000\n",
    "x_QCI0_usage = QCI_usage[0:leng,0]\n",
    "x_QCI1_usage = QCI_usage[0:leng,1]\n",
    "x_QCI2_usage = QCI_usage[0:leng,2]\n",
    "x_QCI3_usage = QCI_usage[0:leng,3]\n",
    "x_QCI4_usage = QCI_usage[0:leng,4]\n",
    "x_QCI5_usage = QCI_usage[0:leng,5]\n",
    "x_QCI6_usage = QCI_usage[0:leng,6]\n",
    "x_QCI7_usage = QCI_usage[0:leng,7]\n",
    "x_QCI8_usage = QCI_usage[0:leng,8]\n",
    "x_QCI9_usage = QCI_usage[0:leng,9]\n",
    "\n",
    "sf_avg = 1400\n",
    "avg_reward_QCI0_usage =[(x_QCI0_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI0_usage),sf_avg)]\n",
    "avg_reward_QCI0_usage = np.array(avg_reward_QCI0_usage)\n",
    "avg_reward_QCI1_usage =[(x_QCI1_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI1_usage),sf_avg)]\n",
    "avg_reward_QCI1_usage = np.array(avg_reward_QCI1_usage)\n",
    "avg_reward_QCI2_usage =[(x_QCI2_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI2_usage),sf_avg)]\n",
    "avg_reward_QCI2_usage = np.array(avg_reward_QCI2_usage)\n",
    "avg_reward_QCI3_usage =[(x_QCI3_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI3_usage),sf_avg)]\n",
    "avg_reward_QCI3_usage = np.array(avg_reward_QCI3_usage)\n",
    "avg_reward_QCI4_usage =[(x_QCI4_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI4_usage),sf_avg)]\n",
    "avg_reward_QCI4_usage = np.array(avg_reward_QCI4_usage)\n",
    "avg_reward_QCI5_usage =[(x_QCI5_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI5_usage),sf_avg)]\n",
    "avg_reward_QCI5_usage = np.array(avg_reward_QCI5_usage)\n",
    "avg_reward_QCI6_usage =[(x_QCI6_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI6_usage),sf_avg)]\n",
    "avg_reward_QCI6_usage = np.array(avg_reward_QCI6_usage)\n",
    "avg_reward_QCI7_usage =[(x_QCI7_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI7_usage),sf_avg)]\n",
    "avg_reward_QCI7_usage = np.array(avg_reward_QCI7_usage)\n",
    "avg_reward_QCI8_usage =[(x_QCI8_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI8_usage),sf_avg)]\n",
    "avg_reward_QCI8_usage = np.array(avg_reward_QCI8_usage)\n",
    "avg_reward_QCI9_usage =[(x_QCI9_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI9_usage),sf_avg)]\n",
    "avg_reward_QCI9_usage = np.array(avg_reward_QCI9_usage)\n",
    "\n",
    "i = np.arange(0,len(avg_reward_QCI1_usage),1)\n",
    "y_QCI0 = avg_reward_QCI0_usage[i]\n",
    "y_QCI1 = avg_reward_QCI1_usage[i]\n",
    "y_QCI2 = avg_reward_QCI2_usage[i]\n",
    "y_QCI3 = avg_reward_QCI3_usage[i]\n",
    "y_QCI4 = avg_reward_QCI4_usage[i]\n",
    "y_QCI5 = avg_reward_QCI5_usage[i]\n",
    "y_QCI6 = avg_reward_QCI6_usage[i]\n",
    "y_QCI7 = avg_reward_QCI7_usage[i]\n",
    "y_QCI8 = avg_reward_QCI8_usage[i]\n",
    "y_QCI9 = avg_reward_QCI9_usage[i]\n",
    "\n",
    "\n",
    "plt.title(\"Resource sharing between QCI  (7 UE with randomly generated CQI, 4 QCI)\")\n",
    "plt.xlabel(\"episod\")\n",
    "plt.ylabel(\"reward\") \n",
    "plt.grid()\n",
    "#plt.plot(i, y_QCI0, label='error',marker='h')\n",
    "plt.plot(i, y_QCI1, label='QCI9',marker='h',color = 'cornflowerblue')\n",
    "#plt.plot(i, y_QCI2, label='QCI2',marker='h') \n",
    "plt.plot(i, y_QCI3, label='QC6',marker='h',color = 'lightcoral') \n",
    "#plt.plot(i, y_QCI4, label='QCI4',marker='h') \n",
    "#plt.plot(i, y_QCI5, label='QCI5',marker='h') \n",
    "plt.plot(i, y_QCI6, label='QCI3',marker='h',color = 'limegreen') \n",
    "#plt.plot(i, y_QCI7, label='QCI7',marker='h') \n",
    "#plt.plot(i, y_QCI8, label='QCI8',marker='h')\n",
    "plt.plot(i, y_QCI9, label='QCI1',marker='h',color = 'r') \n",
    "\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CQI_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CQI_usage[0:leng,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_avg = 100\n",
    "avg_reward_QCI1_usage =[(x_QCI1_usage[j:j+sf_avg].sum())/sf_avg for j in range(0,len(x_QCI1_usage),sf_avg)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_reward_QCI1_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_reward_QCI1_usage = np.array(avg_reward_QCI1_usage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
